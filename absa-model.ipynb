{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:05:33.313025Z","iopub.execute_input":"2022-07-13T11:05:33.313416Z","iopub.status.idle":"2022-07-13T11:06:00.137910Z","shell.execute_reply.started":"2022-07-13T11:05:33.313332Z","shell.execute_reply":"2022-07-13T11:06:00.136680Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1Mn34S75zJpvPMyk9ZfA5kXoUs5skhULD\n# !gdown --id 1-5bdF9W6Ce9AI6YTj0SK8DmVjKFrN94H # phobert_2_task_att\n# !gdown --id 1-00BXOpSHxAm_HUW7gbLWGuoE0N7L7h8 #phobert_2_task_att_v3","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:06:00.140381Z","iopub.execute_input":"2022-07-13T11:06:00.140770Z","iopub.status.idle":"2022-07-13T11:06:04.170646Z","shell.execute_reply.started":"2022-07-13T11:06:00.140732Z","shell.execute_reply":"2022-07-13T11:06:04.169566Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install tokenizers\n!pip install datasets\n!pip install sacrebleu\n!pip install sadice\n# !pip install torchgeometry\n!pip install sentencepiece\n!pip install transformers sentencepiece vncorenlp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-13T11:06:04.172425Z","iopub.execute_input":"2022-07-13T11:06:04.172725Z","iopub.status.idle":"2022-07-13T11:07:19.990261Z","shell.execute_reply.started":"2022-07-13T11:06:04.172699Z","shell.execute_reply":"2022-07-13T11:07:19.989106Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import transformers\nimport pandas as pd\nfrom datasets import load_dataset, load_metric\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport pyarrow as pa\nimport time\nimport timeit\nfrom tqdm.notebook import trange, tqdm\nfrom time import sleep\n\nimport nltk\nimport sacrebleu\nimport torch\nimport torch.nn as nn\n\nfrom sadice import SelfAdjDiceLoss","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:19.993407Z","iopub.execute_input":"2022-07-13T11:07:19.993846Z","iopub.status.idle":"2022-07-13T11:07:23.396458Z","shell.execute_reply.started":"2022-07-13T11:07:19.993802Z","shell.execute_reply":"2022-07-13T11:07:23.395305Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Split data","metadata":{}},{"cell_type":"code","source":"import json\n\npath_memory = \"./memory_edges_3.json\"\n# path_memory = \"../input/model-absa/memory_edges_3.json\"\n\n# Opening JSON file\nwith open(path_memory, 'rb') as openfile:\n    # Reading from json file\n    ls_data_valid = json.load(openfile)\nprint(len(ls_data_valid))\ntext2edge, ls_text, ls_asp, ls_sen = ls_data_valid.values()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:23.398022Z","iopub.execute_input":"2022-07-13T11:07:23.398768Z","iopub.status.idle":"2022-07-13T11:07:23.564966Z","shell.execute_reply.started":"2022-07-13T11:07:23.398737Z","shell.execute_reply":"2022-07-13T11:07:23.563688Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_texts, val_texts, train_tags, val_tags, train_senti, val_senti = train_test_split(ls_text[:], ls_asp[:], ls_sen[:], test_size=.2)\nlen(train_texts), len(val_texts)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:23.566698Z","iopub.execute_input":"2022-07-13T11:07:23.567092Z","iopub.status.idle":"2022-07-13T11:07:23.585804Z","shell.execute_reply.started":"2022-07-13T11:07:23.567053Z","shell.execute_reply":"2022-07-13T11:07:23.584734Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Pretrain phoBERT","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoModel, AutoTokenizer\n# from transformers import BartTokenizerFast, BartphoTokenizer\n# tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\", do_lower_case=True,\\\n#                                              clean_text=True,handle_chinese_chars=True)\n# model_phoBert = AutoModel.from_pretrained(\"vinai/phobert-large\", )","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:23.587356Z","iopub.execute_input":"2022-07-13T11:07:23.587990Z","iopub.status.idle":"2022-07-13T11:07:23.594319Z","shell.execute_reply.started":"2022-07-13T11:07:23.587952Z","shell.execute_reply":"2022-07-13T11:07:23.593195Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Pretrain BARTpho","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoModel, AutoTokenizer\n# from transformers import BartTokenizerFast, BartphoTokenizer\n# tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\", do_lower_case=True,\\\n#                                              clean_text=True,handle_chinese_chars=True)\n# model_bart = AutoModel.from_pretrained(\"vinai/bartpho-word\", )","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:23.596548Z","iopub.execute_input":"2022-07-13T11:07:23.597011Z","iopub.status.idle":"2022-07-13T11:07:23.602923Z","shell.execute_reply.started":"2022-07-13T11:07:23.596973Z","shell.execute_reply":"2022-07-13T11:07:23.601867Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# a = 'giao hàng nhanh nhưng giá cao'\n# tokens = tokenizer(a, return_tensors='pt')\n# feature = model_bart(tokens['input_ids'], tokens['attention_mask'])\n# feature","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:23.603987Z","iopub.execute_input":"2022-07-13T11:07:23.605467Z","iopub.status.idle":"2022-07-13T11:07:23.616917Z","shell.execute_reply.started":"2022-07-13T11:07:23.605430Z","shell.execute_reply":"2022-07-13T11:07:23.616009Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# function for feature","metadata":{}},{"cell_type":"code","source":"def convert_ids_to_string(ids, tokenizer):\n    ls = []\n    for id in ids:\n        # s = tokenizer.convert_tokens_to_string(tokenizer._convert_id_to_token(int(id)))\n        s = tokenizer.convert_ids_to_tokens(int(id))\n        ls.append(s)\n    return ls\n\ndef pair_labels(texts, asp, senti, tokenizer):\n    dict_words = []\n    for i,word in enumerate(texts):\n        ls_id = []\n        tokens = tokenizer.tokenize(word)\n        for token in tokens:\n            # id = tokenizer._convert_token_to_id(token)\n            id = tokenizer.convert_tokens_to_ids(token)\n            ls_id.append(id)\n        dict_words.append([word,ls_id,asp[i],senti[i]])\n    return dict_words\n\ndef balance_labels(texts, asp_label, senti_label):\n    Words = pair_labels(texts, asp_label, senti_label)\n    asp_label_new = []\n    senti_label_new = []\n    texts_new = []\n    for id in Words:\n        for i in id[1]:\n            texts_new.append(tokenizer.convert_ids_to_tokens(i))\n            asp_label_new.append(id[2])\n            senti_label_new.append(id[3])\n    return texts_new,asp_label_new,senti_label_new\n\n\ndef pair_labels_v2(texts, labels):\n    dict_words = []\n    for i,word in enumerate(texts):\n        ls_id = []\n        tokens = tokenizer.tokenize(word)\n        for token in tokens:\n            # id = tokenizer._convert_token_to_id(token)\n            id = tokenizer.convert_tokens_to_ids(token)\n            ls_id.append(id)\n        dict_words.append([word,ls_id,labels[i]])\n    return dict_words    \n\n\ndef balance_labels_v2(texts, labels):\n    Words = pair_labels_v2(texts, labels)\n    label = []\n    texts_new = []\n    for id in Words:\n        for i in id[1]:\n            texts_new.append(tokenizer.convert_ids_to_tokens(i))\n            label.append(id[2])\n            \n    return texts_new, label","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:19:55.519434Z","iopub.execute_input":"2022-07-13T11:19:55.519819Z","iopub.status.idle":"2022-07-13T11:19:55.534052Z","shell.execute_reply.started":"2022-07-13T11:19:55.519791Z","shell.execute_reply":"2022-07-13T11:19:55.532446Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_feature_asp(text, tags, senti):\n    \"\"\"\n    Extract aspect and sentiment for aspect\n        text: separated words in a sentence (list)\n        tags: label aspects of a sentence (list)\n        senti: label sentiments of a sentence (list)\n    \"\"\"\n    memo = {'text':[], 'asp_senti':[], 'label_asp':[]}\n    for j,(t,ap,sen) in enumerate(zip(text,tags,senti)):\n        \n        temp = []\n        if ap == 'B-asp':\n\n            temp.append([text[j], senti[j]])\n            if j+1 < len(tags):\n                try:\n                    while tags[j+1] == 'I-asp':\n                        temp.append([text[j+1], senti[j+1]])\n                        j += 1\n                except IndexError:\n                    continue\n\n            # print(temp)    \n            \n            # Key: text, Value: [asp, senti]             \n            if len(temp) > 1:\n                asp = []\n                for ap in temp:\n                    asp.append(ap[0])\n                aspect = ' '.join(asp)\n                sen = ap[1]\n            else:\n                aspect = temp[0][0]\n                sen = temp[0][1]\n\n            if len(temp) < 1:\n                continue\n            memo['asp_senti'].append([aspect,sen])\n        memo['text'] = ' '.join(text)\n        memo['label_asp'] = tags\n        memo['label_senti'] = senti\n\n    return memo\n\n\n    \ni = 5000\nget_feature_asp(ls_text[i], ls_asp[i], ls_sen[i])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:20:06.569365Z","iopub.execute_input":"2022-07-13T11:20:06.569938Z","iopub.status.idle":"2022-07-13T11:20:06.586326Z","shell.execute_reply.started":"2022-07-13T11:20:06.569901Z","shell.execute_reply":"2022-07-13T11:20:06.585349Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Encode label & WNUT dataset","metadata":{}},{"cell_type":"code","source":"# encoding label\nlabels2id = {'O': 0, 'B-0': 1, 'B-1': 2, 'B-2': 3, 'I-0': 4, 'I-1': 5, 'I-2': 6}\n\ntag2id = {'O': 0, 'B-asp': 1, 'I-asp': 2 }\nid2tag = {id: tag for tag, id in tag2id.items()}\nprint(id2tag)\nsen2id = {'Neg': 0, 'Pos': 1, 'Neu': 2, '-1':3}\nid2sen = {id: sen for sen, id in sen2id.items()}\nprint(id2sen)\n\nsen2id_vn = {'Xấu': 0, 'Tốt': 1, 'Bình thường': 2}\nid2sen_vn = {id: sen for sen, id in sen2id_vn.items()}\nprint(id2sen_vn)\n\nsen2id_2 = {'0': 0, '1': 1, '2': 2, '-1':3}\nid2sen_2 = {id: sen for sen, id in sen2id.items()}\nprint(id2sen)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:07:23.660581Z","iopub.execute_input":"2022-07-13T11:07:23.661068Z","iopub.status.idle":"2022-07-13T11:07:23.674233Z","shell.execute_reply.started":"2022-07-13T11:07:23.661031Z","shell.execute_reply":"2022-07-13T11:07:23.673224Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def encode_tags(texts, aspect, senti, encodings, tokenizer):\n    encoded_label_asp = []\n    encoded_label_senti = []\n    for text, asp, sent, doc_ids in tqdm(zip(texts, aspect, senti, encodings['input_ids']), desc = 'encoding loop'):\n        # create an empty array of -100\n        ids = list(doc_ids)\n\n        doc_enc_label_asp = np.ones(len(ids),dtype=int) * -100\n        doc_enc_label_senti = np.ones(len(ids),dtype=int) * -100\n        Words = pair_labels(text, asp, sent, tokenizer)\n        \n        # indices = [j for j in range(ids.index(0), ids.index(2))]\n        for id in Words:\n            for i in id[1]:\n                # find all index of id\n                # print(ids)\n                indices = [index for index, element in enumerate(ids) if element == i ]\n                for j in indices:\n                    doc_enc_label_asp[j] = tag2id[id[2]]  \n                    doc_enc_label_senti[j] = sen2id_2[id[3]]\n                # <s> and </s>\n                indices = [index for index, element in enumerate(ids) if element == 0 or element == 2]\n                for j in indices:\n                    doc_enc_label_asp[j] =  0\n                    doc_enc_label_senti[j] = -1\n        encoded_label_asp.append(doc_enc_label_asp)\n        encoded_label_senti.append(doc_enc_label_senti)\n\n    return encoded_label_asp, encoded_label_senti\n\n\n# # train_labels_asp, train_labels_sen ,train_encodings = encode_tags(train_texts, train_labels, train_encodings)\n# # val_labels_asp, val_labels_sen ,val_encodings = encode_tags(val_texts, val_labels, val_encodings)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:19:31.434655Z","iopub.execute_input":"2022-07-13T11:19:31.434997Z","iopub.status.idle":"2022-07-13T11:19:31.446497Z","shell.execute_reply.started":"2022-07-13T11:19:31.434969Z","shell.execute_reply":"2022-07-13T11:19:31.445549Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\nfrom transformers import BartTokenizerFast, BartphoTokenizer\n\nclass WNUTDataset_2(torch.utils.data.Dataset):\n    def __init__(self, ls_texts, labels_asp, labels_sen, device, tokenizer = \"phobert\"):\n        \"\"\"\n            ls_texts: separated words of sentences (list of sentences)\n            labels_asp: label aspects (list of sentences)\n            labels_sen: label sentiments (list of sentences)\n            device: \"cpu\" or \"cuda\"\n            tokenizer: tokenize by \"phobert\" or \"bartpho\" (string)\n        \"\"\"\n        if tokenizer.lower() == \"phobert\":\n            tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\", do_lower_case=True,\\\n                                     clean_text=True,handle_chinese_chars=True)\n        else:\n            tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\", do_lower_case=True,\\\n                                     clean_text=True,handle_chinese_chars=True)\n\n        self.ls_texts = ls_texts\n        self.labels_asp = labels_asp\n        self.labels_sen = labels_sen\n\n        self.features =  [get_feature_asp(text, tag, sen) for text,tag,sen in zip(ls_texts[:], labels_asp[:], labels_sen[:]) ]\n\n        texts = [feature['text'] for feature in self.features]\n        \n        self.encoding = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=250)\n        \n        self.texts = texts\n        self.encode_asp, self.encode_senti = encode_tags(ls_texts[:], labels_asp[:], labels_sen[:], self.encoding, tokenizer) \n        self.device = device\n    def __getitem__(self, idx):\n        \n        item = {key: torch.tensor(val[idx]).to(self.device, dtype = torch.long) for key, val in self.encoding.items()}\n        item['ls_texts'] = self.ls_texts[idx]\n        item['encode_asp'] = torch.tensor(self.encode_asp[idx]).to(self.device, dtype = torch.long)\n        item['encode_senti'] = torch.tensor(self.encode_senti[idx]).to(self.device, dtype = torch.long)\n        item['labels_asp'] = self.labels_asp[idx]\n        item['labels_sen'] = self.labels_sen[idx]\n        item['features'] = self.features[idx]\n        item['texts'] = self.texts[idx]\n        return item\n\n    def __len__2(self):\n        return [\"2 labels\", len(self.labels_asp), len(self.labels_sen)]\n    \n    def __len__(self):\n        return len(self.labels_asp)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_dataset_2 = WNUTDataset_2(train_texts, train_tags, train_senti, device, tokenizer = 'phobert')\nval_dataset_2 = WNUTDataset_2(val_texts, val_tags, val_senti, device, tokenizer = 'phobert')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:20:13.740638Z","iopub.execute_input":"2022-07-13T11:20:13.740983Z","iopub.status.idle":"2022-07-13T11:31:21.958488Z","shell.execute_reply.started":"2022-07-13T11:20:13.740955Z","shell.execute_reply":"2022-07-13T11:31:21.957408Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# DATA LOADER\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\nvar = 1\n\n\nloaders = {\n    'train' : DataLoader(train_dataset_2,batch_size = var),\n    'test'  : DataLoader(val_dataset_2,batch_size = var),\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:31:21.960420Z","iopub.execute_input":"2022-07-13T11:31:21.960985Z","iopub.status.idle":"2022-07-13T11:31:21.967400Z","shell.execute_reply.started":"2022-07-13T11:31:21.960944Z","shell.execute_reply":"2022-07-13T11:31:21.966443Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Model senti","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\ndef adjacency_matrix(edges, attention_shape):\n    matrix = torch.zeros(attention_shape[1:])\n    # print(graph)\n    # print('shape:',len(matrix))\n    for [i,j] in edges:\n        # print('shape:',len(matrix),len(matrix[key]))\n#             print(key,i)\n#         if i > attention.shape[1] or j > attention.shape[1]:\n#             continue\n        try:\n            matrix[i,j] = 1\n        except IndexError:\n            continue\n    return matrix\ndef scaled_dot_product(q, k, v,edge,tau = 0.9):\n    devive = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    d_k = q.size()[-1]\n    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n#     attn_logits = F.softmax(attn_logits/tau, dim=-1)\n    attn_logits = attn_logits / np.sqrt(d_k)\n#     print('before softmax: \\n',attn_logits)\n#     print(attn_logits.shape)\n    adj_matrix = adjacency_matrix(edge, attn_logits.shape)\n#     print('adj: \\n',adj_matrix)\n#     attn_logits = torch.mul(adj_matrix.to('cuda'), attn_logits)\n    \n    attention = F.softmax(attn_logits/tau, dim=-1)\n    attention = attention.add(adj_matrix.to(device))\n    values = torch.matmul(attention, v)\n#     print('final attention: \\n',attention)\n    return values, attention\n\n# def scaled_dot_product(q, k, v,tau = 0.9):\n#     devive = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     d_k = q.size()[-1]\n#     attn_logits = torch.matmul(q, k.transpose(-2, -1))\n#     attn_logits = attn_logits / np.sqrt(d_k)\n#     attention = F.softmax(attn_logits/tau, dim=-1)\n#     values = torch.matmul(attention, v)\n#     return values, attention","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:31:21.969060Z","iopub.execute_input":"2022-07-13T11:31:21.969412Z","iopub.status.idle":"2022-07-13T11:31:21.982134Z","shell.execute_reply.started":"2022-07-13T11:31:21.969377Z","shell.execute_reply":"2022-07-13T11:31:21.981160Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"## Test thử\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\nclass ABSA(nn.Module):\n    def __init__(self, pre_model = 'phobert'):\n        '''\n            pre_model: model pre-training \"phobert\" or \"bartpho\" (string)\n        '''\n        super().__init__()\n        self.num_labels_token = 3\n        self.num_labels_sen = 3\n        \n\n        \n        ####### phoBERT #######\n        if pre_model.lower() == 'phobert':\n            self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\", do_lower_case=True,\\\n                                                 clean_text=True,handle_chinese_chars=True)\n            self.model = AutoModel.from_pretrained(\"vinai/phobert-large\")\n        elif pre_model.lower() == 'bartpho':\n        ####### BARTpho ######\n            self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\", do_lower_case=True,\\\n                                                 clean_text=True,handle_chinese_chars=True)\n\n            self.model = AutoModel.from_pretrained(\"vinai/bartpho-word\", )\n            \n        #======== freeze encoder ==========\n#         freeze_module = self.bart.encoder.layers[:]\n#         for param in freeze_module.parameters():\n#             param.requires_grad = False\n            \n        #========= freeze all ========\n        # for param in self.bert.parameters():\n        #     param.requires_grad = False\n    \n        # ======== Layer classifier ===========\n        self.classifier_sen = nn.Linear(1024, 3)\n#         self.classifier_asp = nn.Linear(1024, 3)\n        self.classifier_asp = nn.Linear(1024, 3)\n        \n        # ======= layer GCN for aspect =======\n        self.linearasp_1 = nn.Linear(1024,1024)\n        self.linearasp_2 = nn.Linear(1024,1024)\n        self.linearasp_3 = nn.Linear(1024,1024)\n        \n        # ======== layer GCN for sentiment ======\n        self.linearsen_1 = nn.Linear(1024,1024)\n        self.linearsen_2 = nn.Linear(1024,1024)\n        self.linearsen_3 = nn.Linear(1024,1024)\n    #################################################\n    def forward_GCN_2task(self,\n                   text=None, \n                    input_ids = None, \n                    attention_mask = None, \n                    feature = None,\n                    encode_asp = None,\n                    encode_senti = None,\n                    device = 'cuda',\n                    label_aspect = None, label_senti = None):\n        \n        embedding_1 = self.model(input_ids, attention_mask, output_hidden_states=True)\n        \n        Q_asp = self.linearasp_1(embedding_1['last_hidden_state'])\n        K_asp = self.linearasp_2(embedding_1['last_hidden_state'])\n        V_asp = self.linearasp_3(embedding_1['last_hidden_state'])\n        \n        Values_asp, att_weights_asp = scaled_dot_product(Q_asp,K_asp,V_asp, text2edge[text])\n        logits_token = self.classifier_asp(Values_asp)\n        \n        for label_aspect,label_senti in feature['asp_senti']:\n            text_new = text+\" </s> \"+label_aspect\n            encoding_2 = self.tokenizer(text_new, return_tensors='pt', padding=True, truncation=True, max_length=250).to(device)\n#             ids = torch.cat((input_ids, encoding_2['input_ids']), dim=1)\n#             mask = torch.cat((attention_mask, encoding_2['attention_mask']),dim=1)\n            embedding_2 = self.model(encoding_2['input_ids'],  encoding_2['attention_mask'], output_hidden_states=True)\n            Q_sen = self.linearsen_1(embedding_2['last_hidden_state'])\n            K_sen = self.linearsen_2(embedding_2['last_hidden_state'])\n            V_sen = self.linearsen_3(embedding_2['last_hidden_state'])\n            Values_sen, att_weights_sen = scaled_dot_product(Q_sen,K_sen,V_sen, text2edge[text])\n            output_2 = mean_pooling(Values_sen,encoding_2['attention_mask']).view(-1)\n            logits_sen = self.classifier_sen(output_2)\n            \n        \n    def forward_task2(self,\\\n                      text = None,\n                      input_ids = None,\\\n                      attention_mask = None,\\\n                      feature = None,\\\n                      label_aspect = None,\\\n                      label_senti = None,\\\n                      device = None):\n        # Sentence + aspect => sentiment\n        \n        \n        ##  C1 concat sau khi embedding câu gốc và aspect ===================================================  \n#         embedding_text = self.model(input_ids,  attention_mask, output_hidden_states=True)\n#         encoding_2 = self.tokenizer(label_aspect, return_tensors='pt', padding=True, truncation=True, max_length=250).to(device)\n        \n#         embedding_aspect = self.model(encoding_2['input_ids'],  encoding_2['attention_mask'], output_hidden_states=True)\n        \n#         embedding_concat = torch.cat((embedding_text['last_hidden_state'], embedding_aspect['last_hidden_state']),dim=1)\n#         mask_concat = torch.cat((attention_mask, encoding_2['attention_mask']),dim=1)\n#         output = mean_pooling(embedding_concat,mask_concat).view(-1)\n#         logits_sen = self.classifier_sen(output)\n\n        ##### Compine GCN #####\n#         embedding_text = self.model(input_ids,  attention_mask, output_hidden_states=True)\n#         encoding_2 = self.tokenizer(label_aspect, return_tensors='pt', padding=True, truncation=True, max_length=250).to(device)\n#         embedding_aspect = self.model(encoding_2['input_ids'],  encoding_2['attention_mask'], output_hidden_states=True)\n#         embedding_concat = torch.cat((embedding_text['last_hidden_state'], embedding_aspect['last_hidden_state']),dim=1)\n#         mask_concat = torch.cat((attention_mask, encoding_2['attention_mask']),dim=1)\n#         Q_sen = self.linearsen_1(embedding_concat)\n#         K_sen = self.linearsen_2(embedding_concat)\n#         V_sen = self.linearsen_3(embedding_concat)\n#         Values_sen, att_weights_sen = scaled_dot_product(Q_sen,K_sen,V_sen, text2edge[text])\n#         output = mean_pooling(Values_sen,mask_concat).view(-1)\n#         logits_sen = self.classifier_sen(output)\n    \n        ## C2  Nối câu gốc với aspect ========================================================================\n        text_new = text+\" </s> \"+label_aspect\n        encoding_2 = self.tokenizer(text_new, return_tensors='pt', padding=True, truncation=True, max_length=250).to(device)\n        embedding_2 = self.model(encoding_2['input_ids'],  encoding_2['attention_mask'], output_hidden_states=True)\n        \n#         output = mean_pooling(embedding_2['last_hidden_state'],encoding_2['attention_mask']).view(-1)\n#         logits_sen = self.classifier_sen(output)\n        \n        ##### Compine GCN #####\n        Q_sen = self.linearsen_1(embedding_2['last_hidden_state'])\n        K_sen = self.linearsen_2(embedding_2['last_hidden_state'])\n        V_sen = self.linearsen_3(embedding_2['last_hidden_state'])\n        Values_sen, att_weights_sen = scaled_dot_product(Q_sen,K_sen,V_sen, text2edge[text])\n#         Values_sen, att_weights_sen = scaled_dot_product(Q_sen,K_sen,V_sen)\n        output = mean_pooling(Values_sen,encoding_2['attention_mask']).view(-1)\n        logits_sen = self.classifier_sen(output)\n        \n        loss_sen = None\n        if label_senti is not None:\n            loss_fct_sen = nn.CrossEntropyLoss()\n#             weight_sen = torch.tensor([2., 1., 3.]).to(device)\n#             loss_fct_sen = nn.CrossEntropyLoss(weight = weight_sen)\n            loss_sen = loss_fct_sen(logits_sen, torch.tensor(abs(int(label_senti)), dtype = torch.long).to(device))\n         \n        return logits_sen, loss_sen\n    ####################################################\n    def forward_task1(self, \n                text=None, \n                input_ids = None, \n                attention_mask = None, \n                feature = None,\n                encode_asp = None,\n                encode_senti = None,\n                device = None):\n        # Token classification\n\n#         embedding_1 = self.model(input_ids, attention_mask, output_hidden_states=True)\n#         logits_token = self.classifier_asp(embedding_1['last_hidden_state'])\n        \n        # Compine GCN\n        embedding_1 = self.model(input_ids, attention_mask, output_hidden_states=True)\n        Q_asp = self.linearasp_1(embedding_1['last_hidden_state'])\n        K_asp = self.linearasp_2(embedding_1['last_hidden_state'])\n        V_asp = self.linearasp_3(embedding_1['last_hidden_state'])\n        \n        Values_asp, att_weights_asp = scaled_dot_product(Q_asp,K_asp,V_asp, text2edge[text])\n#         Values_asp, att_weights_asp = scaled_dot_product(Q_asp,K_asp,V_asp)\n        logits_token = self.classifier_asp(Values_asp)\n        \n        loss_asp = None\n        if (encode_asp is not None):\n            weight_token = torch.tensor([1., 10., 10.]).to(device)\n            loss_fct_token = nn.CrossEntropyLoss(weight = weight_token)\n            \n#             loss_fct_token = nn.CrossEntropyLoss()\n\n            # Only keep active parts of the loss\n            if attention_mask is not None:\n                active_loss = attention_mask.view(-1) == 1\n\n                active_logits_token = logits_token.view(-1, self.num_labels_token)\n\n                active_labels_token = torch.where(\n                    active_loss, encode_asp.view(-1), torch.tensor(loss_fct_token.ignore_index).type_as(encode_asp)\n                )\n\n                loss_asp = loss_fct_token(active_logits_token, active_labels_token) \n            else:\n                loss_asp = loss_fct_token(logits_token.view(-1, self.num_labels_token), encode_asp.view(-1))\n        \n        return logits_token, loss_asp\n\n     #########################################   \n    def forward_2_task(self,\n                text=None, \n                input_ids = None, \n                attention_mask = None, \n                feature = None,\n                encode_asp = None,\n                encode_senti = None,\n                device = None,\n                label_aspect = None, label_senti = None,):\n        \n        logits_token, loss_asp = self.forward_task1(\n                                        text= text,\\\n                                        input_ids = input_ids,\\\n                                        attention_mask = attention_mask,\\\n                                        feature = feature,\\\n                                        encode_asp = encode_asp,\\\n                                        encode_senti = encode_senti,\\\n                                        device = device)\n         \n        ls_logits_sen = []\n        loss_tam = 0\n        loss= None\n        for label_aspect,label_senti in feature['asp_senti']:\n            # print(aspect,senti)\n            logits_sen, loss_sen = self.forward_task2(\n                                                text = text,\\\n                                                input_ids = input_ids,\\\n                                                attention_mask = attention_mask,\\\n                                                feature = feature,\\\n                                                device = device,\\\n                                                label_aspect = label_aspect[0], label_senti = label_senti[0])                    \n            loss_tam += loss_sen\n            ls_logits_sen.append(logits_sen)\n        if encode_asp is not None:\n            loss = loss_asp + loss_tam\n        \n        \n        return logits_token, ls_logits_sen, loss\n    #################################################\n    def forward_task3(self, \n                text=None, \n                input_ids = None, \n                attention_mask = None, \n                feature = None,\n                encode_asp = None,\n                encode_senti = None,\n                device = 'cuda'):\n        \n        ls_logits_asp = []\n        loss_tam = 0\n        # feature['asp_senti']: [aspect, senti]\n        for aspect,senti in feature['asp_senti']:\n            encoding_3 = tokenizer(id2sen_vn[int(senti[0])], return_tensors='pt', padding=True, truncation=True, max_length=250).to(device)\n            ids = torch.cat((input_ids, encoding_3['input_ids']), dim=1)\n            mask = torch.cat((attention_mask, encoding_3['attention_mask']),dim=1)\n            embedding_3 = self.bart(ids, mask, output_hidden_states=True)\n            # output_3 = mean_pooling(embedding_3, encoding_3[\"attention_mask\"]).view(-1)\n            logits_token = self.classifier_asp(embedding_3['last_hidden_state'])\n            ls_logits_asp.append(logits_token)\n            encode_asp_label = encode_asp\n\n            if (encode_asp_label is not None):\n                temp = encode_asp_label[0]\n                ls_temp = []\n                for i in range(0, encoding_3['input_ids'].shape[1]):\n                    ls_temp.append(0)\n                temp = torch.cat((temp.to('cpu'),torch.tensor(ls_temp)))\n                # print(temp.shape, torch.reshape(temp, (1,len(temp))).shape)\n                encode_asp_label =  torch.reshape(temp, (1,len(temp))).to(device)\n        \n            loss_fct_token = nn.CrossEntropyLoss()\n\n            # Only keep active parts of the loss\n            if mask is not None:\n                active_loss = mask.view(-1) == 1\n\n                active_logits_token = logits_token.view(-1, self.num_labels_token)\n\n                active_labels_token = torch.where(\n                    active_loss, encode_asp_label.view(-1), torch.tensor(loss_fct_token.ignore_index).type_as(encode_asp_label)\n                )\n\n                loss = loss_fct_token(active_logits_token, active_labels_token) \n            else:\n                loss = loss_fct_token(logits_token.view(-1, self.num_labels_token), encode_asp_label.view(-1))\n            loss_tam += loss\n        loss_asp = loss_tam\n\n        return logits_token, loss_asp\n    ###############################################\n    def forward(self, \n                text=None, \n                input_ids = None, \n                attention_mask = None, \n                feature = None,\n                encode_asp = None,\n                encode_senti = None,\n                device = 'cuda',\n                label_aspect = None, label_senti = None, \n                classes_senti_vn = id2sen_vn, \n                task_1 = False, task_2 = False, task_3 = False, Multi_task = False):      \n\n        # =================================================\n        if task_1:\n            return self.forward_task1(\n                                text= text,\\\n                                input_ids = input_ids,\\\n                                attention_mask = attention_mask,\\\n                                feature = feature,\\\n                                encode_asp = encode_asp,\\\n                                encode_senti = encode_senti,\\\n                                device = device)\n            \n        # =================================================    \n        \n        if task_2:\n            return self.forward_task2(\n                                    text = text,\\\n                                    input_ids = input_ids,\\\n                                    attention_mask = attention_mask,\\\n                                    feature = feature,\\\n                                    label_aspect = label_aspect,\\\n                                    label_senti = label_senti,\\\n                                    device = device,)\n\n        # =================================================\n        \n        if task_3:\n            return self.forward_task3(input_ids = input_ids,\\\n                                attention_mask = attention_mask,\\\n                                feature = feature,\\\n                                encode_asp = encode_asp,\\\n                                encode_senti = encode_senti,\\\n                                device = device)\n        if Multi_task:\n            return self.forward_2_task(\n                            text=text, \n                            input_ids = input_ids, \n                            attention_mask = attention_mask, \n                            feature = feature,\n                            encode_asp = encode_asp,\n                            encode_senti = encode_senti,\n                            device = device)\n                    \n        \n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:31:21.985941Z","iopub.execute_input":"2022-07-13T11:31:21.986351Z","iopub.status.idle":"2022-07-13T11:31:22.040489Z","shell.execute_reply.started":"2022-07-13T11:31:21.986294Z","shell.execute_reply":"2022-07-13T11:31:22.039545Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"import shutil\ndef save_ckp(state, is_best, checkpoint_path, best_model_path):\n    \"\"\"\n    state: checkpoint we want to save\n    is_best: is this the best checkpoint; min validation loss\n    checkpoint_path: path to save checkpoint\n    best_model_path: path to save best model\n    \"\"\"\n    f_path = checkpoint_path\n    # save checkpoint data to the path given, checkpoint_path\n    torch.save(state, f_path)\n    # if it is a best model, min validation loss\n    if is_best:\n        best_fpath = best_model_path\n        # copy that checkpoint file to best path given, best_model_path\n        shutil.copyfile(f_path, best_fpath)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:31:22.043801Z","iopub.execute_input":"2022-07-13T11:31:22.044505Z","iopub.status.idle":"2022-07-13T11:31:22.051597Z","shell.execute_reply.started":"2022-07-13T11:31:22.044468Z","shell.execute_reply":"2022-07-13T11:31:22.050484Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train(start_epochs, n_epochs, valid_loss_min_input,\\\n          data_loaders, device, model, optimizer, checkpoint_path, best_model_path, task = 1):\n    \"\"\"\n    Keyword arguments:\n    start_epochs -- the real part (default 0.0)\n    n_epochs -- the imaginary part (default 0.0)\n    valid_loss_min_input\n    loaders\n    model\n    optimizer\n    criterion\n    use_cuda\n    checkpoint_path\n    best_model_path\n    task: 1,2,3 (AE, APC, Multi_task) (default: 1)\n    returns trained model\n    \"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = valid_loss_min_input \n    \n    \n    loss_tam2 = []\n    ls_train_loss = []\n    ls_eval_loss = []\n\n    \n    \n    for epoch in range(start_epochs, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        # train_loss = 0.0\n        # valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        print(\"\\nStarting training...\")\n        train_start_time = timeit.default_timer()\n        model.train()\n        loss_tam = []\n        for num_senten,data in enumerate(tqdm(data_loaders['train'], desc = 'training loop')):\n            text = data['texts'][0]\n            input_ids = data['input_ids']\n            attention_mask = data['attention_mask']\n            feature = data['features']\n            encode_asp = data['encode_asp']\n\n            ############ output model ############\n            if task == 1:\n                #================= aspect extraction =======================\n                ### zero the parameter gradients        \n                optimizer.zero_grad()\n                logits_asp, loss_asp = model(text, input_ids, attention_mask,\\\n                                             feature, encode_asp,\\\n                                             device = device, task_1 = True)\n                loss_tam.append(loss_asp.item())\n                loss_asp.backward()\n                optimizer.step()\n                \n            elif task == 2:\n                #================= Sentiment for aspects =======================            \n                for aspect,senti in feature['asp_senti']:\n                    optimizer.zero_grad()\n                    logits_sen, loss_sen = model(text, input_ids, attention_mask, \\\n                                                 label_aspect = aspect[0], label_senti = senti[0],\\\n                                                 device = device, task_2 = True)\n                    loss_tam.append(loss_sen.item())\n                    loss_sen.backward()\n                    optimizer.step()\n            else:\n                # ================= Multi task =============================\n                optimizer.zero_grad()\n                logits_asp, logits_sen, loss = model(text, input_ids, attention_mask,\\\n                                                feature = feature, encode_asp = encode_asp,\\\n                                                device = device, Multi_task = True)\n                loss_tam.append(loss.item())\n                loss.backward()\n                optimizer.step()\n                \n        ls_train_loss.append(np.mean(loss_tam))\n                  \n        ######################    \n        # validate the model #\n        ######################    \n        \n        print(\"\\nStarting evaluation...\")\n        model.eval()\n        with torch.no_grad():\n            eval = []     \n            for num_senten,data in enumerate(data_loaders['test']):\n                text = data['texts'][0]\n                input_ids = data['input_ids']\n                attention_mask = data['attention_mask']\n                feature = data['features']\n                encode_asp = data['encode_asp']\n                \n                ############# output model ##############\n                if task == 1:\n                    #================= aspect extraction =======================\n                    logits_asp, loss_asp = model(text, input_ids, attention_mask,\\\n                                                 feature, encode_asp,\\\n                                                 device = device, task_1 = True)\n                    eval.append(loss_asp.item())\n                elif task == 2:\n                    #=========== sentiment for aspects =================\n                    for aspect,senti in feature['asp_senti']:\n                        logits_sen, loss_sen = model(text, input_ids, attention_mask, \\\n                                                     label_aspect = aspect[0], label_senti = senti[0],\\\n                                                     device = device, task_2 = True)\n\n\n                        eval.append(loss_sen.item())\n                else:\n                    # ================= Multi task =============================\n                    logits_asp,logits_sen, loss = model(text, input_ids, attention_mask,\\\n                                                feature = feature, encode_asp = encode_asp,\\\n                                                device = device, Multi_task = True)\n\n                    eval.append(loss.item())\n                    \n        ls_eval_loss.append(np.mean(eval))         \n        # print training/validation statistics\n        print(f\"Time train epoch {epoch}: {timeit.default_timer() - train_start_time }\") \n        print('>>> Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            np.mean(loss_tam),\n            np.mean(eval)\n            ))        \n        loss_tam = []\n        ######################\n        torch.cuda.empty_cache()\n\n        train_loss = ls_train_loss[-1]\n        valid_loss = ls_eval_loss[-1]\n        # create checkpoint variable and add important data\n        checkpoint = {\n            'epoch': epoch + 1,\n            'valid_loss_min': valid_loss,\n            'state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n        }\n        \n        # save checkpoint\n        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n        \n        ## TODO: save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n            # save checkpoint as best model\n            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n            valid_loss_min = valid_loss\n        # Early stop train\n        if epoch >= 2:\n            if train_loss - ls_train_loss[-2] > 0 or valid_loss - ls_eval_loss[-2] > 0:\n                return model,ls_train_loss, ls_eval_loss\n            \n    # return trained model\n    return model,ls_train_loss, ls_eval_loss","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:31:22.053283Z","iopub.execute_input":"2022-07-13T11:31:22.054198Z","iopub.status.idle":"2022-07-13T11:31:22.079113Z","shell.execute_reply.started":"2022-07-13T11:31:22.054045Z","shell.execute_reply":"2022-07-13T11:31:22.078070Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"devive = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ABSA(pre_model='phobert')\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(params) # khoong freeze, train laij pretrained bert\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:31:22.080367Z","iopub.execute_input":"2022-07-13T11:31:22.081427Z","iopub.status.idle":"2022-07-13T11:32:27.240805Z","shell.execute_reply.started":"2022-07-13T11:31:22.081389Z","shell.execute_reply":"2022-07-13T11:32:27.239651Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from datetime import date\nname_model = 'ABSA'\ntoday = date.today()\nd1 = today.strftime(\"%d%m%y\")\nd1","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:32:27.242716Z","iopub.execute_input":"2022-07-13T11:32:27.243083Z","iopub.status.idle":"2022-07-13T11:32:27.250193Z","shell.execute_reply.started":"2022-07-13T11:32:27.243046Z","shell.execute_reply":"2022-07-13T11:32:27.249290Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 3e-7\nweight_decay = 1e-4\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE, weight_decay= weight_decay)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:32:27.251735Z","iopub.execute_input":"2022-07-13T11:32:27.252342Z","iopub.status.idle":"2022-07-13T11:32:27.262578Z","shell.execute_reply.started":"2022-07-13T11:32:27.252307Z","shell.execute_reply":"2022-07-13T11:32:27.261671Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1\npath_checkpoint = f\"/checkpoint_{d1}_ABSA_phoBert_2_task_new_att.pt\"\npath_bestmodel = f\"./best_model_ABSA_phoBert_2_task_new_att.pt\"\ntrained_model, train_loss, valid_loss = train(1, EPOCHS, np.Inf, loaders, device, model, optimizer,\\\n                                              path_checkpoint, path_bestmodel, task = 2)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:32:27.266780Z","iopub.execute_input":"2022-07-13T11:32:27.267087Z","iopub.status.idle":"2022-07-13T11:55:01.871827Z","shell.execute_reply.started":"2022-07-13T11:32:27.267062Z","shell.execute_reply":"2022-07-13T11:55:01.870346Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# %matplotlib inline\n\nimport seaborn as sns\n\n# Use plot styling from seaborn.\nsns.set(style='darkgrid')\n\n# Increase the plot size and font size.\n# sns.set(font_scale=1.5)\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\n# Plot the learning curve.\nplt.plot(train_loss, 'b-o', label=\"training loss\")\nplt.plot(valid_loss, 'r-o', label=\"validation loss\")\n\n# Label the plot.\nplt.title(\"Learning curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:55:01.885732Z","iopub.execute_input":"2022-07-13T11:55:01.900485Z","iopub.status.idle":"2022-07-13T11:55:02.657610Z","shell.execute_reply.started":"2022-07-13T11:55:01.900412Z","shell.execute_reply":"2022-07-13T11:55:02.656324Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"## keep on Train model\n# EPOCHS = 8\n# path_checkpoint = f\"/checkpoint_{d1}_ABSA_2_task.pt\"\n# path_bestmodel = f\"./best_model_ABSA_2_task.pt\"\n# trained_model, train_loss, valid_loss = train(epoch_recall, EPOCHS, loss_recall, loaders, device, model_recall, optimizer_recall,\\\n#                                               path_checkpoint, path_bestmodel)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:55:02.675045Z","iopub.execute_input":"2022-07-13T11:55:02.677940Z","iopub.status.idle":"2022-07-13T11:55:03.155543Z","shell.execute_reply.started":"2022-07-13T11:55:02.677894Z","shell.execute_reply":"2022-07-13T11:55:03.154429Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:55:03.156982Z","iopub.execute_input":"2022-07-13T11:55:03.157488Z","iopub.status.idle":"2022-07-13T11:55:03.820528Z","shell.execute_reply.started":"2022-07-13T11:55:03.157446Z","shell.execute_reply":"2022-07-13T11:55:03.819419Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# PATH = '../input/model-absa/best_model_ABSA_phoBert_sen_v2.pt'\nPATH = './best_model_ABSA_phoBert_2_task_new_att.pt' \nmodel_recall = ABSA()\nLEARNING_RATE = 3e-7\nweight_decay= 1e-4\noptimizer_recall = torch.optim.Adam(params =  model_recall.parameters(), lr=LEARNING_RATE,  weight_decay= weight_decay)\ndevive = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint = torch.load(PATH, map_location=torch.device(device))\nmodel_recall.load_state_dict(checkpoint['state_dict'])\noptimizer_recall.load_state_dict(checkpoint['optimizer'])\nepoch_recall = checkpoint['epoch']\nloss_recall = checkpoint['valid_loss_min']\nmodel_parameters = filter(lambda p: p.requires_grad, model_recall.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(params)\nmodel_recall.to(device)\n# model_recall.eval()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:55:03.821984Z","iopub.execute_input":"2022-07-13T11:55:03.822286Z","iopub.status.idle":"2022-07-13T11:55:45.937951Z","shell.execute_reply.started":"2022-07-13T11:55:03.822237Z","shell.execute_reply":"2022-07-13T11:55:45.936204Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Test model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\ndef evaluate_model_both_task(model, loaders, device, tokenizer = 'phobert', ATE = False, APC = False, M_task = False,\\\n                                classes_asp = tag2id,\\\n                                classes_senti = sen2id_2):\n    \n\n    Result = {'acc_asp': None, 'acc_senti': None , 'F1_asp': None, 'F1_senti': None}\n    eval_data = []\n    n_test_correct, n_test_total = 0,0\n    n_test_senti_correct, n_test_senti_total = 0,0\n    n_test_asp_correct, n_test_asp_total = 0,0\n\n    actual_test_label, model_label = [],[]\n    total_labels_actual, total_labels_predict = [],[]\n    total_asp_predict, total_senti_predict = [],[]\n    total_asp_actual, total_senti_actual = [],[]\n    Wrong_aspect, Wrong_tokens = [],[]\n    model.eval()\n    \n    if tokenizer.lower() == \"phobert\":\n        tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\", do_lower_case=True,\\\n                                 clean_text=True,handle_chinese_chars=True)\n    elif tokenizer.lower() == \"bartpho\":\n        tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\", do_lower_case=True,\\\n                                 clean_text=True,handle_chinese_chars=True)\n        \n\n \n    if isinstance(classes_asp, list) == False or isinstance(classes_senti, list) == False:\n        classes_senti = list(classes_senti)\n        classes_asp = list(classes_asp)\n            \n    for i,data in enumerate(tqdm(loaders['test'], desc='evaluation_model_both_task')):\n        actual_test_senti_label,model_senti_label = [],[]\n        actual_test_asp_label,model_asp_label = [],[]\n        text = data['texts'][0]\n        feature = data['features']  \n        if APC:\n#             if i == 100:\n#                 break\n            label_asp_senti = feature['asp_senti']\n            print('>>> Sentiment for aspects')\n            print('Text: ', text)\n\n            for aspect,senti in label_asp_senti:\n                paraphrase = tokenizer(text, return_tensors=\"pt\").to(device)\n                logits_sen, loss_sen = model(text, paraphrase['input_ids'], paraphrase['attention_mask'],\\\n                                             label_aspect = aspect[0], device = device, task_2 = True)\n                ind = torch.argmax(logits_sen.clone().detach()).item()\n                print('label: ', aspect[0],  senti[0])\n                print('predict: ',aspect[0], ind)\n                actual_test_senti_label.append(int(senti[0]))\n                model_senti_label.append(int(ind))\n            print('='*40)\n        \n        if ATE:\n            \n            paraphrase = tokenizer(text, return_tensors=\"pt\", max_length = 250).to(device)\n            label_asp = np.array(data['labels_asp']).flatten()\n            size = len(paraphrase['input_ids'][0])\n#             print('abc')\n#             if i == 10:\n#                 break\n            logits_asp, loss_asp = model(text, paraphrase['input_ids'], paraphrase['attention_mask'],\\\n                                         feature, device = device, task_1 = True)\n\n        \n            n_test_total += (size-2)\n            tokens = convert_ids_to_string(paraphrase['input_ids'][0], tokenizer)\n            eval_data.append(tokens)\n\n#             print(logits_asp[0].clone().detach())\n            for ix,(u) in enumerate(tqdm(zip(logits_asp[0].clone().detach()), desc = f\"{i}th_sentence\")):\n                try:\n#                     print(u)\n                    ind_u = torch.argmax(u[0].clone().detach()).item()\n                    \n                    if (classes_asp[ind_u] == label_asp[ix-1]): n_test_asp_correct += 1\n                    model_asp_label.append(classes_asp[ind_u])\n                    actual_test_asp_label.append(label_asp[ix-1])\n\n\n                except:\n#                     print('except')\n#                     ind_u = torch.argmax(u[0].clone().detach()).item()\n                    # ind_v = np.argmax(v)\n                    model_asp_label.append('O')\n                    # model_senti_label.append(classes_senti[ind_v])\n                    # actual_test_senti_label.append('-1')\n                    actual_test_asp_label.append('O')\n                \n        if M_task:\n            \n            paraphrase = tokenizer(text, return_tensors=\"pt\", max_length = 250).to(device)\n            label_asp = np.array(data['labels_asp']).flatten()\n            size = len(paraphrase['input_ids'][0])\n            print(size, paraphrase['input_ids'].shape, paraphrase['attention_mask'].shape)\n            logits_asp,ls_logits_sen, loss = model(text, paraphrase['input_ids'], paraphrase['attention_mask'],\\\n                                                   feature, device = device, Multi_task = True)\n\n            label_asp_senti = feature['asp_senti']\n            print('>>> Sentiment for aspects')\n            print('Text: ',text)\n\n            for (aspect,senti),logits_sen in zip(label_asp_senti,ls_logits_sen):\n                ind = torch.argmax(logits_sen.clone().detach()).item()\n                print('label: ', aspect[0],  senti[0])\n                print('predict: ',aspect[0], ind)\n                actual_test_senti_label.append(int(senti[0]))\n                model_senti_label.append(int(ind))\n            print('='*40)\n        \n            n_test_total += (size-2)\n            tokens = convert_ids_to_string(paraphrase['input_ids'][0], tokenizer)\n            eval_data.append(tokens)\n\n#             \n            for ix,(u) in enumerate(tqdm(zip(logits_asp[0].clone().detach()), desc = f\"{i}th_sentence\")):\n                try:\n                    ind_u = torch.argmax(u[0].clone().detach()).item()\n#                     \n                    if (classes_asp[ind_u] == label_asp[ix-1]): n_test_asp_correct += 1\n                    model_asp_label.append(classes_asp[ind_u])\n                    actual_test_asp_label.append(label_asp[ix-1])\n\n\n                except:\n#                   \n#                     ind_u = torch.argmax(u[0].clone().detach()).item()\n                    \n                    model_asp_label.append('O')\n                    \n                    actual_test_asp_label.append('O')\n            \n        \n        \n        accuracy_asp = accuracy_score(actual_test_asp_label, model_asp_label)\n        accuracy_senti = accuracy_score(actual_test_senti_label, model_senti_label)\n\n        print(f\">>> accuracy aspect: {accuracy_asp}\")\n        print(f\">>> accuracy senti: {accuracy_senti}\")\n\n        total_asp_actual.append(actual_test_asp_label)\n        total_senti_actual.append(actual_test_senti_label)\n        total_asp_predict.append(model_asp_label)\n        total_senti_predict.append(model_senti_label)\n\n        \n\n        if accuracy_asp < 0.9:\n            print('>>>>> Token classification <<<<<' )\n            print(\"TOKEN - PREDICT ASP - LABEL ASP\")\n            print('-'*50)\n            print(len(actual_test_asp_label), len(model_asp_label), size)\n            # Wrong_tokens.append(tokens)\n            # Wrong_aspect.append(model_asp_label)\n            for ix in range(size):\n                if ix == 0 or ix == size-1:\n                    print(f\"{tokens[ix]} \\t -- {model_asp_label[ix]}   --   None\")\n                else:\n                    print(f\"{tokens[ix]} \\t -- {model_asp_label[ix]}   --  {actual_test_asp_label[ix]}\")\n            \n        print(\"==========================\")\n        \n\n\n\n\n    # print(list(np.concatenate(total_asp_predict).flat))\n    asp_predict, senti_predict = total_asp_predict, total_senti_predict\n    total_asp_predict = list(np.concatenate(total_asp_predict).flat)\n    total_senti_predict = list(np.concatenate(total_senti_predict).flat)\n    total_asp_actual = list(np.concatenate(total_asp_actual).flat)\n    total_senti_actual = list(np.concatenate(total_senti_actual).flat)\n\n    print('#'*80)\n    print('FINAL')\n    # accuracy = n_test_correct / n_test_total\n    accuracy_asp = accuracy_score(total_asp_actual, total_asp_predict)\n    accuracy_senti = accuracy_score(total_senti_actual, total_senti_predict)\n    # print(f\"accuracy total: {accuracy}\")\n    print(f\"accuracy aspect: {accuracy_asp}\")\n    print(f\"accuracy senti: {accuracy_senti}\")\n    F1_aspect = f1_score(total_asp_actual, total_asp_predict,average='macro')\n    F1_sentiment = f1_score(total_senti_actual, total_senti_predict,average='macro')\n    print(f\"f1_score_ASPECT: {F1_aspect}\",)\n    print(f\"f1_score_SENTIMENT: {F1_sentiment}\")\n    Result['acc_asp'] =  accuracy_asp\n    Result['acc_senti'] = accuracy_senti\n    Result['F1_asp'] = F1_aspect\n    Result['F1_senti'] = F1_sentiment\n    # confusion matrix\n    matrix_senti = confusion_matrix(total_senti_actual,total_senti_predict, labels = [0,1,2])\n    print(f'Confusion matrix for label senti : {classes_senti} \\n{matrix_senti}')\n    matrix_tag = confusion_matrix(total_asp_actual,total_asp_predict, labels = classes_asp)\n    print(f'Confusion matrix for label aspect : {classes_asp} \\n{matrix_tag}')\n    return Result, matrix_senti, matrix_tag, eval_data\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:55:45.939622Z","iopub.execute_input":"2022-07-13T11:55:45.941568Z","iopub.status.idle":"2022-07-13T11:55:45.982271Z","shell.execute_reply.started":"2022-07-13T11:55:45.941518Z","shell.execute_reply":"2022-07-13T11:55:45.981226Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# TO TEST THE NEWLY TRAINED MODEL\n# model = model_both\n\n# TO TEST MODEL_RECAL\nmodel = model_recall\n\n# n = len(val_text[:])\nResult_final, matrix_senti, matrix_tag, eval_data = evaluate_model_both_task(model, loaders, device,\\\n                                                                                    ATE = False, APC = False, M_task = True,\\\n                                                                                    classes_asp = tag2id ,\\\n                                                                                    classes_senti = sen2id_vn)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:55:45.983706Z","iopub.execute_input":"2022-07-13T11:55:45.984143Z","iopub.status.idle":"2022-07-13T11:57:15.301980Z","shell.execute_reply.started":"2022-07-13T11:55:45.984106Z","shell.execute_reply":"2022-07-13T11:57:15.300269Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# END","metadata":{}},{"cell_type":"code","source":"print(Result_final)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:57:15.302945Z","iopub.status.idle":"2022-07-13T11:57:15.304647Z","shell.execute_reply.started":"2022-07-13T11:57:15.304378Z","shell.execute_reply":"2022-07-13T11:57:15.304403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix_tag, matrix_senti","metadata":{"execution":{"iopub.status.busy":"2022-07-13T11:57:15.306408Z","iopub.status.idle":"2022-07-13T11:57:15.306941Z","shell.execute_reply.started":"2022-07-13T11:57:15.306660Z","shell.execute_reply":"2022-07-13T11:57:15.306684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}